<!doctype html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="企業のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="author" content="implementer"><meta name="robots" content="index, follow"><meta property="og:url" content="https://feeds.implementer.net/"><meta property="og:title" content="きしだのHatenaのフィード｜テックブログRSS"><meta property="og:image" content="https://feeds.implementer.net/images/og-image.png"><meta property="og:description" content="企業のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta property="og:type" content="website"><meta property="og:site_name" content="テックブログRSS"><meta property="og:locale" content="ja_JP"><meta name="twitter:card" content="summary"><meta property="twitter:domain" content="https://feeds.implementer.net/"><meta property="twitter:url" content="https://feeds.implementer.net/">
<meta name="twitter:title" content="きしだのHatenaのフィード｜テックブログRSS"><meta name="twitter:description" content="企業のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="twitter:image" content="https://feeds.implementer.net/images/og-image.png"><meta name="thumbnail" content="https://feeds.implementer.net/images/og-image.png"><link rel="preload" href="../../styles/bundle.css" as="style"><link rel="shortcut icon" href="../../images/favicon.ico"><link rel="apple-touch-icon" href="../../images/apple-icon.png"><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="../../feeds/atom.xml"><link rel="alternate" type="application/rss+xml" title="RSS2.0" href="../../feeds/rss.xml"><link rel="alternate" type="application/json" href="../../feeds/feed.json"><link rel="stylesheet" type="text/css" href="../../styles/bundle.css"><script async src="https://www.googletagmanager.com/gtag/js?id=G-CL0G5METXQ"></script><script>
function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-CL0G5METXQ")</script><title>きしだのHatenaのフィード｜テックブログRSS</title></head><body><header role="banner" class="ui-section-header"><div class="ui-layout-container"><div class="ui-section-header__layout ui-layout-flex"><a href="https://feeds.implementer.net/" role="link" aria-label="#"><img src="../../images/icon.png" alt="サイトロゴ" loading="eager" width="96" height="96"> <span class="ui-section-header__title">テックブログRSS</span></a><div class="ui-section-header__links"><a href="https://github.com/ai-implementer/watch-list-feed/" role="link" aria-label="#" target="_blank"><img src="../../images/icon-github.png" alt="GitHubロゴ" loading="eager" width="96" height="96"> </a><a href="https://x.com/" role="link" aria-label="#" target="_blank"><img src="../../images/icon-x.png" alt="Xロゴ" loading="eager" width="96" height="96"></a></div></div></div></header><main role="main"><nav class="ui-nav">
<div class="ui-layout-container"><div class="ui-section-nav__layout ui-layout-flex"><a class="ui-section-nav__link" href="../../">フィード</a> <a class="ui-section-nav__link" href="../../hot/">人気フィード</a> <a class="ui-section-nav__link" href="../../blogs/">ブログ一覧</a></div></div></nav><section class="ui-section-content ui-section-feed"><div class="ui-layout-container"><h2 class="ui-typography-heading">きしだのHatena</h2><div class="ui-container-blog-summary"><div class="ui-blog-summary"><a class="ui-blog-summary__link" href="https://nowokay.hatenablog.com/">https://nowokay.hatenablog.com/</a><p class="ui-blog-summary__description">きしだのHatena</p></div></div><h3 class="ui-typography-heading">フィード</h3><div class="ui-section-content--feature ui-layout-grid ui-layout-grid-3 ui-container-feed ui-container-feed--no-image"><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/09/05/083257"><picture><source type="image/avif" 
srcset="../../images/feed-thumbnails/Ob_oQaOFjT-256.avif 256w, ../../images/feed-thumbnails/Ob_oQaOFjT-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/Ob_oQaOFjT-256.jpeg" width="512" height="287" srcset="../../images/feed-thumbnails/Ob_oQaOFjT-256.jpeg 256w, ../../images/feed-thumbnails/Ob_oQaOFjT-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/09/05/083257">なぜ一度失敗したAIとの会話は打ち切るほうがいいのか</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
AIとやりとりしてると、こんな感じでさっきのバグを再現してしまって「アホか！」って暴言吐きたくなることありますね。 で、このエントリのときに、こういうチャットは捨てて やりなおしたほうがいいと書きました。 AIに激詰めしてしまうのはAIだからじゃなく、そのくらい言わないとわからなそうだから - きしだのHatena なんでそうなるかというと、まずトランスフォーマーのアテンションという単語ごとの関係を見る仕組みがあります。 で、バグコードが続くとき、非常に雑にアテンションを書くとこんな感じで、間違ったコードを強調しあってしまうのですね。どのくらい注目してるか、というのを書いてます。 / / 結構…</div><div class="ui-feed-item__date" title="2025-09-04 23:32:57">2日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/09/01/055716"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/uWmgfYNpfg-256.avif 256w, ../../images/feed-thumbnails/uWmgfYNpfg-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/uWmgfYNpfg-256.jpeg" width="512" height="287" srcset="../../images/feed-thumbnails/uWmgfYNpfg-256.jpeg 256w, ../../images/feed-thumbnails/uWmgfYNpfg-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/09/01/055716">AIに得意かどうかはユニットテストが書きやすいかどうかで判別できる</a><div class="ui-feed-item__hatena-count" title="はてなブックマーク数"><img src="../../images/hatenabookmark-icon.png" alt="はてなブックマークアイコン" loading="lazy" width="96" height="96"> <span>1</span></div><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">AIコーディングエージェントが100倍速くなるエントリに、10000tok/secとTDDとがあればコーディングはガチャになるというブックマークコメントがありました。 AIコーディングエージェントは100倍速くなる - きしだのHatena LLMはじめとした機械学習は、よりよいランダムを選ぶ仕組みです。当たりのランダムが出る確率が高くなるようにパラメータの調整を行うことを「学習」と呼んでいます。こんな感じで、「学習」が進むとハズレが減っていくわけですね。この確率が安定したところが、学習の終了です。 (ChatGPTにでっちあげてもらったイメージ画像) 答えが定義できれば、その答えが出るランダ…</div><div class="ui-feed-item__date" title="2025-08-31 20:57:16">6日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" 
href="https://nowokay.hatenablog.com/entry/2025/08/30/104903"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/guFsidtY18-256.avif 256w, ../../images/feed-thumbnails/guFsidtY18-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/guFsidtY18-256.jpeg" width="512" height="287" srcset="../../images/feed-thumbnails/guFsidtY18-256.jpeg 256w, ../../images/feed-thumbnails/guFsidtY18-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/08/30/104903">AIプログラムの開発演習に使う低消費リソースローカルLLMはQwen3 1.7B Q4がベスト</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
AIプログラムの開発、つまり、AIにコードを書かせるのではなくて、LLMを呼び出したりRAGを実装したりエージェントを作ったりといったAIを組み込むプログラミングの演習をしたいときに、参加者のPCに十分なリソースを前提とできないことは多いと思います。 Java AIプログラミング記事でQwen3 1.7B Q4_K_Mを選んだ 先月gihyo.jpの連載で、「JavaでAIプログラミングをはじめよう」という記事を出しました。 「JavaでAIプログラミングをはじめよう」という短期連載をgihyo.jpで出しました - きしだのHatena そのときに、読者のPCにGPUが載ってたりMacである…</div><div class="ui-feed-item__date" title="2025-08-30 01:49:03">8日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/08/27/041755"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/08/27/041755">AIコーディングエージェントは100倍速くなる</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
CerebrasがQwen3 Coderのホストをして2000tok/secを出してるという話があって、試したいなぁと思ってたのですよ。 Qwen3 Coder 480B is Live on Cerebras ただ、$50/monや$200/monの定額プランは早々に売り切れ。 けど、1M tok/dayまで無料という噂を聞いて、使ってみることにしました。 で、以前つくった雑なエージェントを試す。 Tool Useが効かないDevstralでコーディングエージェントを作る - きしだのHatena そしたら、3秒でSpring BootでのTODOアプリが！これ、ほんとにこの速さで生成してま…</div><div class="ui-feed-item__date" title="2025-08-26 19:17:55">11日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/08/23/221957"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/08/23/221957">LLMで実現されたデザインパターンの夢</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
GoFの「デザインパターン」の「終わりに」という章の「終わりに」という項は次のようになっています。 もっとも良い設計は、全体がたくさんのデザインパターンをぴったりとつなぎ合わせて、組み合わせてできているものである GoFのデザインパターンのコンセプトは、パターンのカタログを提示することだけではなくて、その構成を使って多くのパターンを見出してほしいというものでした。 けど、名前をつけてカタログ化するほどのパターンは、コンピュータの高性能化とネットワークの普及に応じて変化したソフトウェアアーキテクチャを整理したものが多く粒度が大き目で、GoFのデザインパターンの想定した粒度のようなものはあまり共有…</div><div class="ui-feed-item__date" title="2025-08-23 13:19:57">14日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/08/15/130719"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/08/15/130719">AIに激詰めしてしまうのはAIだからじゃなく、そのくらい言わないとわからなそうだから</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
みなさん、AIコーディングしてますか？そうですよね、やってますよね。 みなさん、AIに激詰めしてますか？罵声あびせてますか？やってますよね。 「おめーは何回いえばわかるんだ」みたいなことを、そんなこと書いても意味ないとわかってるのにやってしまいますよね。 ぼくは性格が悪いので、嫌味をいいがちです。 まあ、そうするとキレ気味に「お疲れさまでした！」って言ってくるので、AIかわいい。 これはGPT-4oだったけど、Claude Sonnet 4に聞き直して解決しました。GPT-5ならちゃんと目的完遂できたかもしれません。 で、生身の人間には言わなそうなことを口走ってしまうことも多いわけですね。 で…</div><div class="ui-feed-item__date" title="2025-08-15 04:07:19">22日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/08/13/235311"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/08/13/235311">GPUメモリ4GBあればGPT-oss 20Bが14tok/secで動く</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
llama.cppにMoEに適したCPU/GPUの振り分けのオプションが入って、LM Studioでもそのオプションに対応したことによって、MoEモデルであるGPT-ossが少ないGPUメモリでもそれなりに動くようになりました。拡大するとわかりますが、LM Studioの右下の表示によると、メインメモリは12GBくらい使います。 14tok/sec出ています。 CPUだけで動かすと10tok/secだったので、5割マシですね。 0.3.23.0に「Force Model Expert weight onto CPU」というスイッチが入っているので、これをOnにするとExpertのウェイトがすべ…</div><div class="ui-feed-item__date" title="2025-08-13 14:53:11">24日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/08/11/152751"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/08/11/152751">GPT-5とClaude Sonnet 4でコーディング比較。ChatGPTはツールとして使い物にならない</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
GPT-5が出ましたね。コーディング能力もめっちゃあがってる！みたいなことが書いてあるので、いろいろ試してみました。 開発者向け GPT-5 のご紹介 | OpenAI 結論を書いておくと、GPT-5のコーディング能力は確かにあがってSonnet 4と同等くらいになってるけど、ChatGPTというサービスがコーディングツールとして使い物にならなくなっていました。 チャットUIでコード書くならClaude。 マリオ なんかマリオができるという話だったので、やってみました。 javaのswingでリアルなマリオのようなゲームを作って。 1ソースで完結して。 背景もかわいいほうがいい。 だいぶいいで…</div><div class="ui-feed-item__date" title="2025-08-11 06:27:51">1ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/08/08/204357"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/08/08/204357">「JavaでAIプログラミングをはじめよう」という短期連載をgihyo.jpで出しました</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
技評さんのサイトで「JavaでAIプログラミングをはじめよう」という短期連載をやってました。 LLMを動かして接続してRAGやMCPも組んでひととおりやってみるという連載になってます。 JavaでAIプログラミングをはじめよう 記事一覧 | gihyo.jp ● 初回は、LM Studioを使ってQwen3 1.7Bをローカルで動かしてHttpClientで呼び出すという、準備的な回。 今ならGPT-oss 20Bでもいいかもしれないけど、Qwen3 1.7Bのほうがどんな環境でも動くんじゃないかと思います。 JavaでLLMにアクセスしてみよう | gihyo.jp ● 第2回は、定番ライブ…</div><div class="ui-feed-item__date" title="2025-08-08 11:43:57">1ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/08/06/063849"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/08/06/063849">OpenAIのオープンモデルGPT-oss 20Bがすごすぎる</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
OpenAIのオープンモデルが来ました。 120Bと20B。どちらもMoEで、アクティブパラメータはそれぞれ5.1B、3.6Bです。 そして4bit浮動小数点での量子化があるので、120Bは80GBのVRAM、20Bは16GBのVRAMで動きます。 Introducing gpt-oss | OpenAI LM Studioで動かす。早い！速い！ LM Studioに即来ていました。早い！ 最新版にしてllama.cppも更新が必要です。 追記: 0.3.22-b1で正式にgpt-ossに対応したようです。記事を書いた時点での0.3.21-b4では対応が不完全だったらしい。 起動時にgpt-o…</div><div class="ui-feed-item__date" title="2025-08-05 21:38:49">1ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/08/02/161039"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/08/02/161039">Qwen3-235BやQwen3-30B、Qwen3 Coder Flashは長コンテキストでの性能劣化が激しいのでは</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
Qwen3のアップデートがいろいろ出ていて、ベンチマークですごい結果を出したりしています。 けど、実際に使うと全然そんな性能が出てる気しないです。 これたぶん、コンテキストが長くなったときの性能劣化が激しいんじゃないかと思います。 なので、ベンチマークや、ちょっとプロンプト一発投げて返答を見ると性能よさそうに見えるんだけど、実際に使うとダメということになるんだと思います。 Qwen3 30Bアップデートとコーディングモデル Qwen3のアップデートは、先日の235Bに続いて、30B-A3Bのnon-thinkingモデルと、それをベースにしたコーディングモデルが出ていました。 Qwen/Qwe…</div><div class="ui-feed-item__date" title="2025-08-02 07:10:39">1ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/07/26/135300"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/07/26/135300">Qwen3 235Bのコーディング力は相変わらず低い。Qwen3 Coderは期待できる。</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
アリババのQwen3 235Bがアップデートされて、reasoningとnon-reasoningが分離しました。また、Qwen3 Coderという480Bのコーディング用モデルも出ていたので、砂時計を実装させて試してみました。 Qwen3-235B-A22B-Thinking-2507はコーディングに期待できない Qwen3 235Bのアップデートは、先にnon-reasoningなモデルが出ていましたが、reasoningモデルも出てきました。 🚀 We’re excited to introduce Qwen3-235B-A22B-Thinking-2507 — our most adv…</div><div class="ui-feed-item__date" title="2025-07-26 04:53:00">1ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/07/23/062925"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/07/23/062925">Jakarta EEは、なぜJakartaなのにApache財団ではなくEclipse財団管理なのか</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
Java EEはOracleの元を離れてEclipse財団に寄贈されJakarta EEになりました。 このJakartaという名前は、Apache財団でのJava系プロジェクトを管理するプロジェクトの名前で、TomcatやMavenなども最初はJakartaの下にありました。 略称がJEEになるような名前でJavaに親和性が高いということで最終候補に残り、もうひとつの候補であるEnterprise Profileに対して、65%の支持をえて決まったのだと思います。 であれば、Apache財団に寄贈しないのはなぜってなりますが、スポンサーみたらわかりますね。 Eclipse財団のトップレベルス…</div><div class="ui-feed-item__date" title="2025-07-22 21:29:25">1ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/07/18/043533"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/07/18/043533">他組織のAIエージェントをA2Aで呼び出すのは非現実的かも</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
エージェントとエージェントで通信するA2Aプロトコルで、さまざまなエージェントがやりとりする世界みたいなのが描かれがちだけど、組織をまたがって自分たちでコントロールできないエージェントにシステムが依存するのってあまり現実的じゃないなと思ったのでまとめてみます。 図解するとこう。他組織のエージェントで、内部でMCPやFunction Callingを呼び出しているものを、自組織のエージェントからA2Aで呼び出すという構造。 ただ、他の組織が自分の組織のためにエージェントを作ってくれているということはなくて、ユーザーが人間として使うエージェントをこちらのエージェントから呼び出してるということになる…</div><div class="ui-feed-item__date" title="2025-07-17 19:35:33">2ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/07/12/191038"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/07/12/191038">オブジェクト指向のサンプルプログラムがだいたいヒドい理由</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
いまだにオブジェクト指向とか言ってるのか、という話ですが、いまだに「プログラミングの勉強はじめました。オブジェクト指向が目標です！」みたいなのがThreadsに流れてきたりして、いつまでも無くならんなぁと思うわけですよ。 で、まあオブジェクト指向を勉強してしまいたくなるのは仕方がないとして、オブジェクト指向推しの本でのサンプルがだいたいヒドいのが問題だなと思ったわけです。 アプリケーションを見据えていない オブジェクト指向の例として、自転車クラスだとか勇者クラスだとか定義するサンプルをみかけます。 自転車クラスを作る例の場合、車輪クラスがありサドルクラスがありペダルクラスがあり、ブレーキクラス…</div><div class="ui-feed-item__date" title="2025-07-12 10:10:38">2ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/06/26/224437"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/06/26/224437">AIの世界も「フリーランチは終わった」になってきてるのでは</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
去年くらいに作ったRAGなどAI関連のシステムを、単に今年4月のモデルに差し替えるだけで性能向上した、というのはいろいろなところであるように思います。 コーディングエージェントが、一部先進的な人だけではなく広く使われだしたのも、2月のClaude 3.7や5月にClaude 4による性能向上があってこそだと思います。 ただ、こういった、モデルを差し替えるだけでなんでも性能向上するというのは終わりつつある気がします。 2004年ごろまで続いたCPUのクロック向上が終わって、CPUを差し替えるだけで何でも性能向上する時代が終わったときに「フリーランチは終わった」と言われました。マルチコアによる並列…</div><div class="ui-feed-item__date" title="2025-06-26 13:44:37">2ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/06/23/113527"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/06/23/113527">AIでプログラマ不要になるというのは、プログラミング言語構文わかればプログラム組めるという誤解に基づくのでは</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
AIで日本語で指示をあたえればプログラムを作ってくれるようになって、プログラミング知識がなくても誰でもプログラムが組めるとか、プログラマが不要になるとかいう話が盛り上がってますね。 けど、実際にプログラマをやって、AIコーディングエージェントを使っていれば、プログラミング知識がなくても可能な領域というのはそんなに広くないことを感じていると思います。 たとえば、ほぼプロンプト一発で作ってもらった刺身タンポポゲームがあります。 このプロンプトはこんな感じです。 刺身にタンポポを乗せるゲームをJavaのSwingで作って。 刺身かネコが0.75秒ごとに表示されます。 刺身は、白い皿に、赤い板状の切り…</div><div class="ui-feed-item__date" title="2025-06-23 02:35:27">2ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/06/10/023240"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/06/10/023240">Tool Useが効かないDevstralでコーディングエージェントを作る</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
Mistal.aiからMistral 3.1 Smallをベースにしたコーディング専用モデルDevstralが出ていたので、これを使ってエージェントを作ろうと思ったのです。 Devstral | Mistral AI Devstralは、24Bというサイズで他の大きなオープンウェイトモデルも凌駕するコーディング性能を出しています。 ベンチマークは当てにならないことも多いですが、使い比べた実感としても確かにQwen3 235B-A22BやDeepSeekよりもコードを書くという印象です。 これを、以前作った、Tool Use(Function Calling)を使った雑なコーディングエージェント…</div><div class="ui-feed-item__date" title="2025-06-09 17:32:40">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/06/05/113733"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/06/05/113733">OuteTTSでテキストの音声化を試す</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
OuteTTSというののv1.0が出てたので試してみました。 前回のブログ内の文章を適当に読ませてみました。 風邪ひいてるときに読んだマンガ - きしだのHatena 「勇者」「美女」を読めなかったり「平和」が「ピンフ」になったりするので、書き換えています。あと、英語女性話者のプロファイルしかないので、英語訛りになってますね。 OuteTTSというT2Sモデルを試すけど、日本語の読み上げは微妙・・・なんか以前のバージョンにあった日本語話者プロファイルとかがなくて、英語女性話者しかない。 pic.twitter.com/PT6b0mlcta— きしだൠ(K1S) (@kis) 2025年6月5日…</div><div class="ui-feed-item__date" title="2025-06-05 02:37:33">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/06/02/195916"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/06/02/195916">風邪ひいてるときに読んだマンガ</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
風邪ひいて土日は寝てたりして、だいぶマンガを雑に読んでたので面白かったののメモ。 異世界多し。 気絶勇者と暗殺姫 勇者を暗殺するために美女３人がパーティーを組んで暗殺を狙うという話だけど、裏切りとかもなく平和。 6/14まで2巻まで無料で読める。 気絶勇者と暗殺姫【電子単行本】 1 (少年チャンピオン・コミックス)作者:雪田幸路,のりしろちゃん秋田書店Amazon 凶乱令嬢ニア・リストン 死にかけ病弱令嬢に転移して、最強令嬢で悪い人をのしていくやつ。 強すぎていい。 ところで、異世界に生まれなおすのが転生で、異世界にそのまま若返ったりしつつ移動するのが転移なんだけど、死んだ人の肉体に魂だけ入る…</div><div class="ui-feed-item__date" title="2025-06-02 10:59:16">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/05/30/084705"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/05/30/084705">AIエージェントの流れはAGI(汎用人口知能)から一旦離れる流れ</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
AIコーディングエージェントが流行りだしてますね。 AIコーディングエージェントでは、いろいろなロジカルな処理でLLMを制御することで、プログラミングの計画をたて実装してテスト、修正といった流れを実行します。 このAIコーディングエージェントを病院の診察室に持っていっても、うまく診療したりしませんね。 診療のためのエージェントは診療エージェントとして特別に実装する必要があります。 つまり、AIエージェントって独自実装で専門家していきます。 エージェントの核になるLLMは、どのような要件にも使える汎用の知能部品です。LLMが賢くなる流れは、AGI(汎用知能)に近づくものだったと思います。 けど、…</div><div class="ui-feed-item__date" title="2025-05-29 23:47:05">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/05/29/091302"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/05/29/091302">LLMの日本知識を測るのに山口県について聞くのがよかった</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
「山口県の特徴は？」でLLMの日本語知識が割と測れる気がしたので16GB VRAMで動く範囲でいくつかオープンモデルを試しました。 結論としては、日本語でのチャットなど日本語表現力が必要なら、オープンモデルではGemma3一択。 法律や商慣習に関わる処理や観光地での案内に使うなど、確実な日本知識が必要な場合、また1GB程度のサイズで日本語応対する場合などはLLM-jp-3がおすすめです。 Gemma3、Qwen3、ABEMA Qwen2.5 32B Japanese、LLM-jp-3、Sarashina2.2を試していきます。 Gemma3 まずGemma3。27Bで見てみます。 「石見銀山」…</div><div class="ui-feed-item__date" title="2025-05-29 00:13:02">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/05/12/224052"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/05/12/224052">古いコードを捨てて1から書き直したからこそ続いているソフトウェア</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
Joel on SoftwareにNetScapeを例に、古いプログラムを捨てて1から書き直したくなるのは戦略ミスだって書いてあるけど、あのとき書き直してなかったら続いてないんではって思ったので、1から書き直して続いてるソフトウェアを挙げてみる。 Firefox NetScapeからMozillaに移行するときに、新バージョンのリリースがなくなって、そこで致命的にシェアを落としたというのは確かにそうだと思う。 けど、そこで書き換えていなかったら、2005年のAJAXから始まるWebアプリの高度化についていけなかったと思う。 あそこで書き換えたからこそ、いまこの記事をFirefox上で書けてるん…</div><div class="ui-feed-item__date" title="2025-05-12 13:40:52">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/05/11/233150"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/05/11/233150">CPUが得意なことをCPUにまかせて少ないVRAMでも大きめのLLMを速く動かす</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
Redditに「VRAM足りないとき一部のレイヤーをCPUに任せるんではなく、レイヤー全部をGPUに載せてレイヤー内部のFFNだけCPUに持っていったら速くなった、なんでこれが標準じゃないんだ」というのがあったので、おうちのRTX 4060 Ti 16GBで試してみたら微妙に速くなりました。 https://www.reddit.com/r/LocalLLaMA/comments/1ki7tg7/dont_offload_gguf_layers_offload_tensors_200_gen/ Qwen3 30B A3Bで試してみる こういった指定がOllamaやLM Studioではできない…</div><div class="ui-feed-item__date" title="2025-05-11 14:31:50">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/05/09/002001"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/05/09/002001">クソデカオープンモデルではLlama4が最強かもしれない</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
もう全人類128GBとか512GBとか載ったMacを手にいれてクソデカモデルを試すようになっていますね。 ぼくもMac Studio 512GBを1日借りてて試したのだけど、Llama4がなんだかんだで強いという印象でした。 ※2025/8/27追記 もちろん、Qwen3 CoderやKimi K2など、この後でてきた強いクソデカオープンモデルに抜かれてます。 クソデカモデルの選択肢としては次のようなものがあります。512GB Macで動かしたときの数字も参考までに。 モデル パラメータ数 アクティブ コンテキスト長 マルチモーダル 量子化 推論速度 LLama4 Maverick 400B …</div><div class="ui-feed-item__date" title="2025-05-08 15:20:01">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/05/05/134853"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/05/05/134853">Grokが仕事してないのにもうすぐできますって嘘ついてきたので、Geminiに差し替えるていったら、人間性は勝ってるので、と言い出す</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
GrokにXの投稿の傾向を解析してもらえるか聞いてみたら、できます！というのでお願いしたけど、いつまでもうだうだ理由つけてやらないので、Geminiと置き換えるぞ！っていったら、「「性能はGeminiにいさんが勝ってるけど人格いいので！伸びしろあるんで！2050年になったらちゃんとやります！」みたいなことを言ってて面白かったまとめ。 週間ニュースのまとめはじめました。 Grokのいいわけ いろいろ聞かれて、計算はじめるよって言ってくる。 取得中らしい そもそもGrokにバックグラウンドで計算して通知する仕組みあるんか？なさそうだけど。 といいながら進捗50% ここまで来て、アカウント正しいんか…</div><div class="ui-feed-item__date" title="2025-05-05 04:48:53">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/04/30/024927"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/04/30/024927">Qwen3はローカルLLMの世界を変えたかも</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
Qwen3が出ていて、14Bを中心にいろいろ試したのだけど、かなり使い物になって、日常的な用途ではこれでいいのでは、という感じもします。 4BでもGPT-4oを越えているという話もありますが、確かに単純な用途ではGPT-4oの代わりにしてもいいなと場面も割とありそうな出力です。さすがにちょっと込み入ったものだと4oだけど。 1.7Bなど小さいモデルも既存のモデルより使えるものになっていて、ローカルLLMの世界を変えそう。 解説動画も撮りました。 週間ニュースのまとめはじめました。 サイズとしては0.6B, 1.7B, 4B, 8B, 14B, 32Bと、MoEモデルの30B-A3B, 235B…</div><div class="ui-feed-item__date" title="2025-04-29 17:49:27">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/04/26/105712"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/04/26/105712">今のAIの急激な進化は、今までの遅れを取り戻しただけで、これからは普通の成長速度になるんでは</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
この2年半くらいで急激にAIが進化して、このままの速度で進化が進むように見えるけど、今までディープニューラルネットや自然言語処理が目立たなかったところに、急に注目されてリソースが投入されて時代が追いついただけな気がする。 H100というハードウェアはChatGPT直前にリリースされていて、どこそこが数万台導入みたいなときにはすでにこなれていた。 GPUを連携させてニューラルネットの学習をさせる技術もだいぶこなれていた。 学習に投入するデータもだいぶあふれていた。 自然言語処理の知見も結構蓄積されてた。 それがチャットができるようになったことで注目されて、H100をフルに使って人材や知見を投入し…</div><div class="ui-feed-item__date" title="2025-04-26 01:57:12">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/04/25/030248"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/04/25/030248">LangChain4Jで雑なAIコーディングエージェントを作る</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
ぼくもAIコーディングエージェントを作ったほうがいいんじゃないか、ということで、かろうじてコーディングエージェントと呼べるものを作りました。 指示したJavaファイルを作って保存して実行してエラー出なくなるまでやりなおすというものです。 ただまあ、このレベルだと、コーディングエージェントといっても、ファイル読み書きとコード実行ができればいいと思います。 なので、とりあえずこんな感じでsaveCodeとexecuteCodeのTool Callingを用意。見易さのためにUI関係の処理は削ってます。 @Tool(&quot;&quot;&quot; save the code into the file with givin…</div><div class="ui-feed-item__date" title="2025-04-24 18:02:48">4ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://nowokay.hatenablog.com/entry/2025/04/23/233712"><img src="../../images/alternate-feed-image.png" alt="記事のアイキャッチ画像" loading="lazy" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://nowokay.hatenablog.com/entry/2025/04/23/233712">Windowsで1.58bit推論モデル、BitNetを試す</a><div class="ui-feed-item__blog-title">きしだのHatena</div><div class="ui-feed-item__summary">
1, 0, -1の3値で重みを表現するBitNet b1.58の、独自に4兆トークンで学習した2Bモデルが出ていたので試しました。 https://github.com/microsoft/BitNet だいたいReadmeの通りにやればいいんだけど、Windowsではハマリポイントあったのでメモ。Readme見れば書いてあるんだけど、見逃しがち。 まず、VS2022が必要、そしてVS2022コマンドプロンプトでの実行が必要です。 Visual Studio 2022 コミュニティ エディション – 最新の無料バージョンをダウンロードする 必要なコンポーネントも書いてあるけど、日本語での表記は…</div><div class="ui-feed-item__date" title="2025-04-23 14:37:12">4ヶ月前</div></div></div></div></div></section></main><footer role="contentinfo" class="ui-section-footer"><div class="ui-layout-container"><div class="ui-layout-column-6 ui-layout-column-center"><div class="ui-component-cta ui-layout-flex ui-section-footer__site-info"><p class="ui-text-note">このサイトは<br>記事を読んでその企業の技術・カルチャーを知れることや<br>質の高い技術情報を得られることを目的としています。</p><p class="ui-text-note">追加したいブログがある場合は<br><a href="https://github.com/ai-implementer/watch-list-feed#%E3%82%B5%E3%82%A4%E3%83%88%E3%81%AE%E8%BF%BD%E5%8A%A0%E6%96%B9%E6%B3%95" target="_blank">サイトの追加方法</a> をご参照ください。</p></div></div></div><div class="ui-layout-container"><div 
class="ui-section-footer__layout ui-layout-flex"><p class="ui-section-footer--copyright ui-text-note"><a class="ui-text-note" href="https://github.com/ai-implementer/" target="_blank"><small>@implementer</small></a></p><a href="https://github.com/ai-implementer/watch-list-feed/" role="link" aria-label="#" class="ui-text-note" target="_blank"><small>GitHub</small></a></div></div></footer></body></html>