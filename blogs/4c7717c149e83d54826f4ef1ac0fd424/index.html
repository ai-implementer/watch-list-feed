<!doctype html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="企業のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="author" content="implementer"><meta name="robots" content="index, follow"><meta property="og:url" content="https://feeds.implementer.net/"><meta property="og:title" content="Zennの「LLM」のフィードのフィード｜テックブログRSS"><meta property="og:image" content="https://feeds.implementer.net/images/og-image.png"><meta property="og:description" content="企業のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta property="og:type" content="website"><meta property="og:site_name" content="テックブログRSS"><meta property="og:locale" content="ja_JP"><meta name="twitter:card" content="summary"><meta property="twitter:domain" content="https://feeds.implementer.net/"><meta property="twitter:url" 
content="https://feeds.implementer.net/"><meta name="twitter:title" content="Zennの「LLM」のフィードのフィード｜テックブログRSS"><meta name="twitter:description" content="企業のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="twitter:image" content="https://feeds.implementer.net/images/og-image.png"><meta name="thumbnail" content="https://feeds.implementer.net/images/og-image.png"><link rel="preload" href="../../styles/bundle.css" as="style"><link rel="shortcut icon" href="../../images/favicon.ico"><link rel="apple-touch-icon" href="../../images/apple-icon.png"><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="../../feeds/atom.xml"><link rel="alternate" type="application/rss+xml" title="RSS2.0" href="../../feeds/rss.xml"><link rel="alternate" type="application/json" href="../../feeds/feed.json"><link rel="stylesheet" type="text/css" href="../../styles/bundle.css"><script async 
src="https://www.googletagmanager.com/gtag/js?id=G-CL0G5METXQ"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-CL0G5METXQ")</script><title>Zennの「LLM」のフィードのフィード｜テックブログRSS</title></head><body><header role="banner" class="ui-section-header"><div class="ui-layout-container"><div class="ui-section-header__layout ui-layout-flex"><a href="https://feeds.implementer.net/" role="link" aria-label="#"><img src="../../images/icon.png" alt="サイトロゴ" loading="eager" width="96" height="96"> <span class="ui-section-header__title">テックブログRSS</span></a><div class="ui-section-header__links"><a href="https://github.com/ai-implementer/watch-list-feed/" role="link" aria-label="#" target="_blank"><img src="../../images/icon-github.png" alt="GitHubロゴ" loading="eager" width="96" height="96"> </a><a href="https://x.com/" role="link" aria-label="#" target="_blank"><img src="../../images/icon-x.png" alt="Xロゴ" loading="eager" 
width="96" height="96"></a></div></div></div></header><main role="main"><nav class="ui-nav"><div class="ui-layout-container"><div class="ui-section-nav__layout ui-layout-flex"><a class="ui-section-nav__link" href="../../">フィード</a> <a class="ui-section-nav__link" href="../../hot/">人気フィード</a> <a class="ui-section-nav__link" href="../../blogs/">ブログ一覧</a></div></div></nav><section class="ui-section-content ui-section-feed"><div class="ui-layout-container"><h2 class="ui-typography-heading">Zennの「LLM」のフィード</h2><div class="ui-container-blog-summary"><div class="ui-blog-summary"><a class="ui-blog-summary__link" href="https://zenn.dev/topics/llm">https://zenn.dev/topics/llm</a><p class="ui-blog-summary__description"></p></div></div><h3 class="ui-typography-heading">フィード</h3><div class="ui-section-content--feature ui-layout-grid ui-layout-grid-3 ui-container-feed ui-container-feed--no-image"><div class="ui-feed-item"><a class="ui-feed-item__og-image" 
href="https://zenn.dev/arai0711/articles/orca_role_playing_blog"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/lMXjIOF5zc-256.avif 256w, ../../images/feed-thumbnails/lMXjIOF5zc-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/lMXjIOF5zc-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/lMXjIOF5zc-256.jpeg 256w, ../../images/feed-thumbnails/lMXjIOF5zc-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/arai0711/articles/orca_role_playing_blog">BigFiveを統合してLLMのロールプレイ能力向上に関する論文を一緒に読みましょう！</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">
ORCA: Big Five を統合して LLM のロールプレイ能力を底上げするこの記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと同じ目線で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！ TL;DRORCAは，ユーザの Big Five（各6サブ次元=計35次元） に基づく性格特性を，データ拡張と指示調整を通じて LLM のロールプレイに組み込む枠組み．4段構成：①性格推定→②データ拡張（プロフィール/潜在知識/心理活動）→③PCIP（性格条件付き指示プロンプト）でのデータ化→④PTI...</div><div class="ui-feed-item__date" title="2025-09-06 07:19:17">8時間前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/arai0711/articles/personalized_dialogue_agents_blog"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/wn8ETDKC1L-256.avif 256w, ../../images/feed-thumbnails/wn8ETDKC1L-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/wn8ETDKC1L-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/wn8ETDKC1L-256.jpeg 256w, ../../images/feed-thumbnails/wn8ETDKC1L-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/arai0711/articles/personalized_dialogue_agents_blog">動的ペルソナ適応で進化する対話エージェントに関する論文を一緒に読みましょう！</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">SPDA: 会話中に“自分のペルソナ”を進化させる個人化対話エージェントこの記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと同じ目線で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！ TL;DRSPDA（Self-evolving Personalized Dialogue Agents）は，対話の最中にエージェント自身のペルソナを動的に更新してユーザに徐々に合わせ込む枠組み．属性レベルとプロフィール（全体）レベルの二段で適応し，整合性チェックで矛盾を回避する．テストベッドは Emo...</div><div class="ui-feed-item__date" title="2025-09-06 05:45:31">9時間前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/knowledgework/articles/learning-context-engineering"><picture><source type="image/avif" 
srcset="../../images/feed-thumbnails/nO3ladHyyq-256.avif 256w, ../../images/feed-thumbnails/nO3ladHyyq-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/nO3ladHyyq-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/nO3ladHyyq-256.jpeg 256w, ../../images/feed-thumbnails/nO3ladHyyq-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/knowledgework/articles/learning-context-engineering">AIが“思った通りに動かない”理由とコンテキストエンジニアリング</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">
この記事について!この記事は「KNOWLEDGE WORK Blog Sprint 2025」の一環として公開されています。（ナレッジワークのエンジニアが、9月の1か月間リレー形式で記事を発信する企画です） TL;DRAIが「思った通りに動かない」のは、単なるモデルの能力不足ではなく、 情報設計 の問題が大きい情報を増やすだけでは逆効果になることもあり、 整理・最適化して渡す 「コンテキストエンジニアリング」が鍵 となるこれはプロンプトの工夫を超えた “情報の物流設計” であり、AI活用の新しい必須スキルである この記事の分量と内容本記事は 約15分前後で...</div><div class="ui-feed-item__date" title="2025-09-06 03:00:05">12時間前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/bigmac123/articles/e6a44638445bcb"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/f0gbtgwvXl-256.avif 256w, ../../images/feed-thumbnails/f0gbtgwvXl-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/f0gbtgwvXl-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/f0gbtgwvXl-256.jpeg 256w, ../../images/feed-thumbnails/f0gbtgwvXl-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/bigmac123/articles/e6a44638445bcb">LLMメモをサクッと整理</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">1. OpenAI 系列 GPT-4o &amp; GPT-4.1GPT-4o：複雑な推論・高精度タスク向け。マルチモーダル（画像/動画対応）。GPT-4o-mini：要約・翻訳など軽量タスク向け。GPT-3.5の後継。GPT-4.1（2025年中）：速度・コスト効率改善。精度とリソースのバランス◎。汎用〜高度用途まで対応。 o1 &amp; o3 系列 — AGIに最も近い？o1（2024年9月）：超高精度・超高コスト（GPT-4o-miniの30倍以上）。o3（2025年初）：ARC-AGI：87.5%（人間トップは87%）→ AGIレベルと...</div><div class="ui-feed-item__date" title="2025-09-06 02:54:41">12時間前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/japan/articles/82d80f0764ecc2"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/0pfHvMr4IW-256.avif 256w, ../../images/feed-thumbnails/0pfHvMr4IW-512.avif 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/0pfHvMr4IW-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/0pfHvMr4IW-256.jpeg 256w, ../../images/feed-thumbnails/0pfHvMr4IW-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/japan/articles/82d80f0764ecc2">LoRA入門：軽量な大規模言語モデルのファインチューニング手法</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">大規模言語モデル（LLM）は高性能ですが、そのままファインチューニングすると膨大な計算リソースやストレージを必要とします。例えば、数十億パラメータを持つモデル全体を更新するのは現実的ではありません。そこで登場するのが LoRA（Low-Rank Adaptation） です。LoRAは「全パラメータを更新する代わりに、低ランク行列を追加して学習」する手法で、以下のような特徴があります。低コスト：更新するパラメータがごく一部に限られる高速：GPUメモリ使用量が大幅に削減される柔軟：複数のLoRAアダプタを組み合わせて利用可能本記事では、LoRAを使ったファインチューニン...</div><div 
class="ui-feed-item__date" title="2025-09-05 13:51:10">1日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/headwaters/articles/ad5d05ae791e55"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/oK76M2zYGe-256.avif 256w, ../../images/feed-thumbnails/oK76M2zYGe-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/oK76M2zYGe-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/oK76M2zYGe-256.jpeg 256w, ../../images/feed-thumbnails/oK76M2zYGe-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/headwaters/articles/ad5d05ae791e55">やばいSLMを見つけてしまった</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div 
class="ui-feed-item__summary">その名も「Doge」...https://huggingface.co/SmallDoge/Doge-60M-Instruct ポイント1. 怪しい挿絵が怪しい。関連論文著者の連絡先がGmailというのも怪しい。 ポイント2. モデルサイズモデルが小さすぎる。重みファイルがBF16で100MBほどしかない。あのQwen3-0.6Bやapple/FastVLM-0.5Bですら、BF16で1.5GBぐらいのサイズである。https://huggingface.co/Qwen/Qwen3-0.6B/tree/mainhttps://huggingface.co/a...</div><div class="ui-feed-item__date" title="2025-09-05 10:33:42">1日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/arai0711/articles/ld_agent_longterm_blog"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/Ia95wEBm0O-256.avif 256w, ../../images/feed-thumbnails/Ia95wEBm0O-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/Ia95wEBm0O-256.jpeg" width="512" height="268" 
srcset="../../images/feed-thumbnails/Ia95wEBm0O-256.jpeg 256w, ../../images/feed-thumbnails/Ia95wEBm0O-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/arai0711/articles/ld_agent_longterm_blog">長期対話を“イベント記憶×ペルソナ”で支える LLMに関する論文を一緒に読みましょう！</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">LD-Agent: 長期対話を“イベント記憶×ペルソナ”で支える LLM パーソナライズド・エージェントこの記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと同じ目線で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！ TL;DRLD-Agent は長期・マルチセッション対話のためのモデル非依存フレームワーク．①イベント知覚（長期/短期メモリ），②ペルソナ抽出（ユーザ/エージェント双方），③応答生成の3モジュールで構成し，取得したメモリとペルソナを統合して応答を誘導します．長期メモリは...</div><div class="ui-feed-item__date" title="2025-09-05 09:52:23">1日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/lotation/articles/ae314647f06d2c"><picture>
<source type="image/avif" srcset="../../images/feed-thumbnails/ofjDCR_Fkz-256.avif 256w, ../../images/feed-thumbnails/ofjDCR_Fkz-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/ofjDCR_Fkz-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/ofjDCR_Fkz-256.jpeg 256w, ../../images/feed-thumbnails/ofjDCR_Fkz-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/lotation/articles/ae314647f06d2c">&quot;TODOリストのサイクル&quot;を常に回しながらAIを働かせたら、コードレビューの認知負荷が激減した話</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">
※ 約2分で読めます!この記事は人間が100%書きましたもはや何番煎じか分からない「AIにTODOリストを書かせる」という発想が、意外にも、あとから 「人間が」『AIは&quot;なぜ&quot;そのコードを書いたのか？』を追跡するのに役立つことに気付いたよ、というお話です。※ いま流行りの仕様駆動開発のお話ではありません。 何を解決する記事なのか皆さん、コーディングAgent（Claude Code, Codex, GitHub Copilot...）を使っていますか？きっと使っていますよね。確か、つい半年か1年前くらいまでは、AIには小さな関数や機能単位でコードを書かせていたよう...</div><div class="ui-feed-item__date" title="2025-09-05 06:06:56">1日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/tfutada/articles/68dd0e19d92279"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/Zah8amKyuj-256.avif 256w, ../../images/feed-thumbnails/Zah8amKyuj-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/Zah8amKyuj-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/Zah8amKyuj-256.jpeg 256w, ../../images/feed-thumbnails/Zah8amKyuj-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/tfutada/articles/68dd0e19d92279">GoogleのNER LangExtractでエンティティ抽出をやってみた</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">本記事は、Google謹製の文章からエンティティを抽出するPythonライブラリLangExtractの紹介になります。ユースケースとしては、ニュース記事などの非構造化データから、人物名など特定のキーワードを抽出し、文章にタグをつけたり、グラフDBを作成することで、RAGのコンテキストの精度を高めることができます。!後でご紹介しますが、天気のニュース記事から、日付、地域、天候を抽出することが可能です。これにより、曖昧な非構造化データを、正規化した構造化データに変換することが可能です。 インストール方法Pythonのライブラリをインストールします。langextractの...</div><div class="ui-feed-item__date" title="2025-09-05 05:48:58">1日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/noranuko13/articles/f28099c1d636ab"><picture><source type="image/avif" 
srcset="../../images/feed-thumbnails/lnBqvXhE4F-256.avif 256w, ../../images/feed-thumbnails/lnBqvXhE4F-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/lnBqvXhE4F-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/lnBqvXhE4F-256.jpeg 256w, ../../images/feed-thumbnails/lnBqvXhE4F-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/noranuko13/articles/f28099c1d636ab">【LLM】心配性なAI開発初心者がClaude Code CLIを使うまでと今後</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">
はじめに 対象何から始めたらいいか分からないので、誰かのムーブを参考にしたい人向け。石橋を叩きながら三歩進んで二歩下がるITエンジニア向け。 記事の趣旨最近話題のChatGPTやClaude Code、正直今も困ってないけど凄そうだ。しかし心配性で、腰が重くて、守銭奴のように財布の紐が固くて、何かと言い訳をしつつ、まだ触ってないという方は多いのではないかと思います。私も少し前までそうでした。何なら今でも20日やそこら触っただけのぺいぺいです。とはいえ、触るまでに何をしたのか。触ってみてどうだったのか。今後どうしていくつもりなのか。この辺りの経験や感想...</div><div class="ui-feed-item__date" title="2025-09-05 03:03:01">1日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/loglass/articles/b140077acdecab"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/Kk8UP3Kk-L-256.avif 256w, ../../images/feed-thumbnails/Kk8UP3Kk-L-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/Kk8UP3Kk-L-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/Kk8UP3Kk-L-256.jpeg 256w, ../../images/feed-thumbnails/Kk8UP3Kk-L-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/loglass/articles/b140077acdecab">【実例付き】オレオレ！ MCP Server デザインパターン【汎用Agentへの熟練知のプラグイン】</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">!2025/7/24のイベント「MCPは当たり前になるのか？ 〜流行から普及への可能性〜」での発表スライドを大きく加筆・再編集したものになりますクライアントの推論能力を借りて思考を伴うタスクを実装できる samplingやhuman in the loopとしての elicitationは面白いな〜と思っているので、よければそこだけでも見てみてください。 1. コンセプト昨今、アプリケーション開発に変化が生じています。（toBの例で考えます。）「ドメインエキスパートの熟練知識をシステムに写す」という面は変わっていませんが、「非定型・非決定論的判断」「実行を伴う知恵寄りの...</div><div class="ui-feed-item__date" title="2025-09-04 22:53:30">2日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/kiyoka/articles/learning-rag-1"><picture><source type="image/avif" 
srcset="../../images/feed-thumbnails/jWTGNUizZg-256.avif 256w, ../../images/feed-thumbnails/jWTGNUizZg-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/jWTGNUizZg-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/jWTGNUizZg-256.jpeg 256w, ../../images/feed-thumbnails/jWTGNUizZg-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/kiyoka/articles/learning-rag-1">RAGをMVP（Minimum Viable Product）を作って試してみた</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">
はじめに最近RAGに興味を持ち、勉強がてらllama-indexなどで遊んでいました。しかし、自分用のユースケースを見つけられず、「これは便利！」と感じるものは出来ませんでした。そこで代替案として、エンジニア向けに、こんなサービスがあったら良いだろうなと思うものを考案し、実際にMVPとして試してみたので共有します。 AWSのクラウドデザインパターンというMVPMVP（Minimum Viable Product）という考え方があります。MVPとは、最小限の機能で実際に動作し、ユーザーに価値を提供できる製品のことです。例えば、SNSアプリを作る場合、最初から高度な機能（動...</div><div class="ui-feed-item__date" title="2025-09-04 13:59:27">2日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/arai0711/articles/personalize_lm_humanfeedback_blog"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/pOOcnZRkWk-256.avif 256w, ../../images/feed-thumbnails/pOOcnZRkWk-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/pOOcnZRkWk-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/pOOcnZRkWk-256.jpeg 256w, ../../images/feed-thumbnails/pOOcnZRkWk-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/arai0711/articles/personalize_lm_humanfeedback_blog">個人化されたフィードバックから学ぶLLMに関する論文を一緒に読みましょう！</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">Personalized-RLHF (P-RLHF) — 個人化された人間フィードバックから学ぶLLMの新定式化この記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと同じ目線で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！著作権の関係で画像は掲載できないので，論文をぜひご一読ください！ TL;DR課題：従来のRLHF（およびDPO）は“すべての人間の好みは同じ分布から来る”という一様性仮定を暗に置く．これは多数派の好みを“総意”として学習してしまい，少数派の好みを無視しがち．著者らは...</div><div class="ui-feed-item__date" title="2025-09-04 09:20:04">2日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/arai0711/articles/persona_plug_personalization_blog"><picture><source type="image/avif" 
srcset="../../images/feed-thumbnails/fSLEMK3KrL-256.avif 256w, ../../images/feed-thumbnails/fSLEMK3KrL-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/fSLEMK3KrL-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/fSLEMK3KrL-256.jpeg 256w, ../../images/feed-thumbnails/fSLEMK3KrL-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/arai0711/articles/persona_plug_personalization_blog">履歴を1つの埋め込みに凝縮して差し込むLLMに関する論文を一緒に読みましょう！</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">
Persona-Plug (PPlug) でLLMを個人化：履歴を1つの埋め込みに凝縮して差し込むこの記事は，「自分の理解を深めたい」という気持ちで書いています．読者のみなさんと同じ目線で，一緒に理解を育てていくスタイルです．僕の理解が及ばない部分があれば，優しく教えていただけると幸いです！ TL;DRPPlugは，ユーザ履歴全体を1つの“個人埋め込み” に凝縮し，LLMの入力に前置するだけで個人化を実現する枠組み．LLM本体のパラメータは固定のまま（plug-and-play）．LaMPベンチマークの6タスクで既存の微調整型やリトリーバル型を +1.4%〜+35....</div><div class="ui-feed-item__date" title="2025-09-04 09:20:03">2日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/tdmn/articles/0df5db61305961"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/jE1d6EhY4z-256.avif 256w, ../../images/feed-thumbnails/jE1d6EhY4z-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/jE1d6EhY4z-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/jE1d6EhY4z-256.jpeg 256w, ../../images/feed-thumbnails/jE1d6EhY4z-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/tdmn/articles/0df5db61305961">Claude Codeの開発効率を劇的に改善するSuperClaudeフレームワーク完全ガイド</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">1. はじめに 1.1 SuperClaudeとはSuperClaude は、Claude Codeを拡張し、体系的な開発フローを実現するフレームワークです。スラッシュコマンド、ペルソナ（専門家ロール）、MCPサーバ連携などの機能を統合的に提供し、開発プロセス全体の効率化を支援します。主な特徴：統一されたスラッシュコマンド体系: /sc:* 形式で分析・設計・実装・テスト・ドキュメント生成を網羅ペルソナ機能: architect、security、qaなど、各専門領域に特化した応答モードを提供行動モード: 省トークンモード、設計志向モード、調査志向モードなど、タ...</div><div class="ui-feed-item__date" title="2025-09-04 02:46:06">3日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/kimkiyong/articles/708647490ab14e"><picture><source type="image/avif" 
srcset="../../images/feed-thumbnails/Up50ZrR7MZ-256.avif 256w, ../../images/feed-thumbnails/Up50ZrR7MZ-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/Up50ZrR7MZ-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/Up50ZrR7MZ-256.jpeg 256w, ../../images/feed-thumbnails/Up50ZrR7MZ-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/kimkiyong/articles/708647490ab14e">spec-kit徹底解剖：AI時代の仕様駆動開発を実現するツールキットの内部構造</a><div class="ui-feed-item__hatena-count" title="はてなブックマーク数"><img src="../../images/hatenabookmark-icon.png" alt="はてなブックマークアイコン" loading="lazy" width="96" height="96"> <span>1</span></div><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">
はじめにGitHubが2025年9月にオープンソースとしてリリースした「Spec Kit」は、従来の「コード優先」から「仕様優先」への開発パラダイムシフトを実現するツールキットです。AIコーディングエージェントと連携し、曖昧なプロンプトから明確な仕様、実装計画、タスク分解、そして動作するコードまでを体系的に生成する革新的なアプローチを提供しています。本記事では、spec-kitの内部構造から実装方法論まで、技術者が実践的に活用するための詳細な解説を行います。 spec-kitとは何か？ 従来開発手法の課題これまでのAIコーディングでは「vibe-coding」と呼ばれる...</div><div class="ui-feed-item__date" title="2025-09-04 02:32:12">3日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/m_nakano_teppei/articles/f08dad0b520906"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/WAC7llTlvI-256.avif 256w, ../../images/feed-thumbnails/WAC7llTlvI-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/WAC7llTlvI-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/WAC7llTlvI-256.jpeg 256w, ../../images/feed-thumbnails/WAC7llTlvI-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/m_nakano_teppei/articles/f08dad0b520906">初学者向け~SentencePiece完全ガイド：現代LLMを支える多言語トークナイザーの仕組み</a><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">はじめにChatGPTやLLaMAなど、現代の大規模言語モデル（LLM）が自然に多言語を処理できる背景には、SentencePieceという革新的なトークナイザー技術があります。「トークナイザーなんて、ただ文章を単語に分けるだけでしょ？」と思っていませんか？実は、SentencePieceは従来のトークナイザーとは全く違うアプローチで、AI業界に革命をもたらした技術なのです。この記事では、SentencePieceの基本概念から実装の詳細まで、技術者向けに詳しく解説します。 SentencePieceとは何か？ 従来の問題点従来のトークナイザーには深刻な問題がありまし...</div><div class="ui-feed-item__date" title="2025-09-04 01:07:38">3日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/tsurubee/articles/1383f86eee4825"><picture><source type="image/avif" 
srcset="../../images/feed-thumbnails/yNoh9z5kPL-256.avif 256w, ../../images/feed-thumbnails/yNoh9z5kPL-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/yNoh9z5kPL-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/yNoh9z5kPL-256.jpeg 256w, ../../images/feed-thumbnails/yNoh9z5kPL-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/tsurubee/articles/1383f86eee4825">信頼できるLLM-as-a-Judgeの構築に向けた研究動向</a><div class="ui-feed-item__hatena-count" title="はてなブックマーク数"><img src="../../images/hatenabookmark-icon.png" alt="はてなブックマークアイコン" loading="lazy" width="96" height="96"> <span>2</span></div><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">
近年、大規模言語モデル（LLM）は自然言語処理から科学研究、教育、法律、金融まで幅広く応用され、その柔軟な生成能力は社会や研究のあり方を大きく変えている。しかし、その柔軟さゆえに出力の評価は難しい。最も確実なのは専門家によるマニュアル評価だが、コストと時間がかかりスケールしにくいという課題がある。この解決策として注目されているのがLLM-as-a-Judgeである。これは、LLMに「ジャッジ（評価者）」の役割を担わせ、人間のような文脈理解と判断力を活かしつつ自動化によるスケーラビリティを実現するアプローチである。しかし現状のLLM-as-a-Judgeは、まだ「信頼できる評価者」と呼ぶに...</div><div class="ui-feed-item__date" title="2025-09-04 00:41:20">3日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://zenn.dev/demouth/articles/99a2fdaf92a71f"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/m0p94SQrzy-256.avif 256w, ../../images/feed-thumbnails/m0p94SQrzy-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/m0p94SQrzy-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/m0p94SQrzy-256.jpeg 256w, ../../images/feed-thumbnails/m0p94SQrzy-512.jpeg 512w" 
sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/demouth/articles/99a2fdaf92a71f">最近のMCPの仕様拡張（2025年9月）</a><div class="ui-feed-item__hatena-count" title="はてなブックマーク数"><img src="../../images/hatenabookmark-icon.png" alt="はてなブックマークアイコン" loading="lazy" width="96" height="96"> <span>2</span></div><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">MCPの仕様拡張について調べました。個人的に２つ気になったものがあったので記事に残しておこうと思います。 ① Enhance authorization server discovery with support for OpenID Connect Discovery 1.0. (PR #797)この変更は、「MCP Authorization」の仕様を拡張するものになります。2025-06-18 版の「MCP Authorization」の仕様では、未認可の MCP Client が Authorization Server にアクセスすると Authorization Se...</div><div class="ui-feed-item__date" title="2025-09-03 23:55:04">3日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" 
href="https://zenn.dev/ml_bear/articles/b58004bf5a3e6c"><picture><source type="image/avif" srcset="../../images/feed-thumbnails/ZWXwM8i4b7-256.avif 256w, ../../images/feed-thumbnails/ZWXwM8i4b7-512.avif 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"><img alt="記事のアイキャッチ画像" loading="lazy" src="../../images/feed-thumbnails/ZWXwM8i4b7-256.jpeg" width="512" height="268" srcset="../../images/feed-thumbnails/ZWXwM8i4b7-256.jpeg 256w, ../../images/feed-thumbnails/ZWXwM8i4b7-512.jpeg 512w" sizes="(min-width: 75rem) 16rem, (min-width: 64rem) 19rem, (min-width: 48rem) 19rem, 8rem"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://zenn.dev/ml_bear/articles/b58004bf5a3e6c">Google公式の Nano Banana プロンプトテンプレートが参考になったので試してみた</a><div class="ui-feed-item__hatena-count" title="はてなブックマーク数"><img src="../../images/hatenabookmark-icon.png" alt="はてなブックマークアイコン" loading="lazy" width="96" height="96"> <span>348</span>
</div><div class="ui-feed-item__blog-title">Zennの「LLM」のフィード</div><div class="ui-feed-item__summary">これはなに？Google AI Studio が以下のX投稿で Nano Banana 向けのプロンプトテンプレートを公開していました。個人的に画像生成のPromptingはあまり経験がなく、写経しながら試してみたところ「こんなに詳しく書かないとまともな絵が出てこないのね」と勉強になったので備忘録としてメモを残します📝https://x.com/googleaistudio/status/1962957615262224511以下、ガイドに書かれていた原則、および、日本語で試す際の注意点に少し触れたのち、プロンプトテンプレートの日本語版とそれを実際に僕が試した事例の紹介へと進...</div><div class="ui-feed-item__date" title="2025-09-03 23:54:43">3日前</div></div></div></div></div></section></main><footer role="contentinfo" class="ui-section-footer"><div class="ui-layout-container"><div class="ui-layout-column-6 ui-layout-column-center"><div class="ui-component-cta ui-layout-flex ui-section-footer__site-info"><p class="ui-text-note">このサイトは<br>記事を読んでその企業の技術・カルチャーを知れることや<br>質の高い技術情報を得られることを目的としています。</p><p class="ui-text-note">追加したいブログがある場合は<br><a href="https://github.com/ai-implementer/watch-list-feed#%E3%82%B5%E3%82%A4%E3%83%88%E3%81%AE%E8%BF%BD%E5%8A%A0%E6%96%B9%E6%B3%95" 
target="_blank">サイトの追加方法</a> をご参照ください。</p></div></div></div><div class="ui-layout-container"><div class="ui-section-footer__layout ui-layout-flex"><p class="ui-section-footer--copyright ui-text-note"><a class="ui-text-note" href="https://github.com/ai-implementer/" target="_blank"><small>@implementer</small></a></p><a href="https://github.com/ai-implementer/watch-list-feed/" role="link" aria-label="#" class="ui-text-note" target="_blank"><small>GitHub</small></a></div></div></footer></body></html>